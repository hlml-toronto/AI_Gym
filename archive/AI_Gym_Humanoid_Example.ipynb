{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humanoid AI Gym\n",
    "\n",
    "This notebook is a template for training the humanoid robot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "No module named 'mujoco_py'. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\duncan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmujoco_py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mujoco_py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5005fe0a2935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmujoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmujoco_env\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duncan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gym\\envs\\mujoco\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmujoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmujoco_env\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMujocoEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# ^^^^^ so that user gets the correct error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# message if mujoco is not installed correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmujoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mant\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAntEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmujoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhalf_cheetah\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHalfCheetahEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duncan\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmujoco_py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mDEFAULT_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: No module named 'mujoco_py'. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gym.envs.mujoco import mujoco_env\n",
    "from gym import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables are used for defining the actions and states of the game \"LunarLander-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SPACE = 8\n",
    "ACTION_SPACE = 4\n",
    "ENV = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# actions\n",
    "DO_NOTHING = 0\n",
    "LEFT_ENGINE = 1\n",
    "MAIN_ENGINE = 2\n",
    "RIGHT_ENGINE = 3\n",
    "\n",
    "# state\n",
    "X_POS = 0\n",
    "Y_POS = 1\n",
    "X_SPEED = 2\n",
    "Y_SPEED = 3\n",
    "ANGLE = 4\n",
    "ANGLE_SPEED = 5\n",
    "FIRST_LEG = 6\n",
    "SECOND_LEG = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the basic interface with the game. The game is essentially a very rapid turn-based game. In each round, there are 2 main steps:\n",
    "1. An action is taken by the agent.\n",
    "2. The game updates according to its current state and the input action from the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_center(model, sim):\n",
    "    mass = np.expand_dims(model.body_mass, 1)\n",
    "    xpos = sim.data.xipos\n",
    "    return (np.sum(mass * xpos, 0) / np.sum(mass))[0]\n",
    "\n",
    "class HumanoidEnv(mujoco_env.MujocoEnv, utils.EzPickle):\n",
    "    def __init__(self):\n",
    "        mujoco_env.MujocoEnv.__init__(self, 'humanoid.xml', 5)\n",
    "        utils.EzPickle.__init__(self)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        data = self.sim.data\n",
    "        return np.concatenate([data.qpos.flat[2:],\n",
    "                               data.qvel.flat,\n",
    "                               data.cinert.flat,\n",
    "                               data.cvel.flat,\n",
    "                               data.qfrc_actuator.flat,\n",
    "                               data.cfrc_ext.flat])\n",
    "\n",
    "    def step(self, a):\n",
    "        pos_before = mass_center(self.model, self.sim)\n",
    "        self.do_simulation(a, self.frame_skip)\n",
    "        pos_after = mass_center(self.model, self.sim)\n",
    "        alive_bonus = 5.0\n",
    "        data = self.sim.data\n",
    "        lin_vel_cost = 1.25 * (pos_after - pos_before) / self.dt\n",
    "        quad_ctrl_cost = 0.1 * np.square(data.ctrl).sum()\n",
    "        quad_impact_cost = .5e-6 * np.square(data.cfrc_ext).sum()\n",
    "        quad_impact_cost = min(quad_impact_cost, 10)\n",
    "        reward = lin_vel_cost - quad_ctrl_cost - quad_impact_cost + alive_bonus\n",
    "        qpos = self.sim.data.qpos\n",
    "        done = bool((qpos[2] < 1.0) or (qpos[2] > 2.0))\n",
    "        return self._get_obs(), reward, done, dict(reward_linvel=lin_vel_cost, reward_quadctrl=-quad_ctrl_cost, reward_alive=alive_bonus, reward_impact=-quad_impact_cost)\n",
    "\n",
    "    def reset_model(self):\n",
    "        c = 0.01\n",
    "        self.set_state(\n",
    "            self.init_qpos + self.np_random.uniform(low=-c, high=c, size=self.model.nq),\n",
    "            self.init_qvel + self.np_random.uniform(low=-c, high=c, size=self.model.nv,)\n",
    "        )\n",
    "        return self._get_obs()\n",
    "\n",
    "    def viewer_setup(self):\n",
    "        self.viewer.cam.trackbodyid = 1\n",
    "        self.viewer.cam.distance = self.model.stat.extent * 1.0\n",
    "        self.viewer.cam.lookat[2] = 2.0\n",
    "        self.viewer.cam.elevation = -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define a couple of test agents to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent(state):\n",
    "    \"\"\"This agent returns random actions.\"\"\"\n",
    "    return int(np.random.rand() * 4)\n",
    "\n",
    "\n",
    "def stupid_agent(state):\n",
    "    \"\"\"A very simple expert system.\"\"\"\n",
    "    if state[FIRST_LEG] == 1 and state[SECOND_LEG] == 1:\n",
    "        return DO_NOTHING\n",
    "    if state[Y_SPEED] < -0.2:\n",
    "        return MAIN_ENGINE\n",
    "    if state[ANGLE] < -0.1:\n",
    "        return LEFT_ENGINE\n",
    "    if state[ANGLE] > 0.1:\n",
    "        return RIGHT_ENGINE\n",
    "    return DO_NOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216.4407724587458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agent = stupid_agent\n",
    "play_game(my_agent, ENV, show=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n, agent):\n",
    "    cum_fitness = 0\n",
    "    for i in range(n):\n",
    "        fitness = play_game(agent, ENV, show=False, verbose=False)\n",
    "        cum_fitness += fitness\n",
    "    return cum_fitness\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
